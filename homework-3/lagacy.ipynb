{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/anaconda3/envs/wimu-hw3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, BertPreTrainedModel, BertModel\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchcrf import CRF\n",
    "from tqdm import tqdm\n",
    "\n",
    "class config:\n",
    "    root_dir = ''\n",
    "    data_dir = root_dir + 'data/example_datasets_msra/'\n",
    "    model_dir = root_dir + 'checkpoints/a'\n",
    "    load_before = False\n",
    "    # bert_model = 'microsoft/deberta-v3-large'\n",
    "    # bert_model = 'microsoft/mdeberta-v3-base'\n",
    "    bert_model = 'bert-base-uncased'\n",
    "    device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # train config\n",
    "    output_dir = 'outputs/'\n",
    "    overwrite_output_dir = True\n",
    "    epoch_num = 5\n",
    "    min_epoch_num = 3\n",
    "    # batch_size = 36\n",
    "    batch_size = 32\n",
    "    fp16 = True\n",
    "    test_split_size = 0.2\n",
    "    learning_rate = 3e-5\n",
    "    weight_decay = 0.01\n",
    "    clip_grad = 5\n",
    "    patience = 0.0002\n",
    "    patience_num = 10\n",
    "    max_sequence_length = 256\n",
    "\n",
    "    labels = ['location', 'person', 'organization']\n",
    "    label2id = {\n",
    "        'O': 0,\n",
    "        'B-PER': 1,\n",
    "        'I-PER': 2,\n",
    "        'B-ORG': 3,\n",
    "        'I-ORG': 4,\n",
    "        'B-LOC': 5,\n",
    "        'I-LOC': 6,\n",
    "    }\n",
    "\n",
    "    id2label = {_id: _label for _label, _id in list(label2id.items())}\n",
    "    num_labels = len(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:device: cuda:3\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.info(\"device: {}\".format(config.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Reusing dataset msra_ner (/home/jovyan/.cache/huggingface/datasets/msra_ner/msra_ner/1.0.0/5ce47bc7f8da59fd9d0ad08d185fa72f5576b614f136a56e82c7669d22ea5cfe)\n"
     ]
    }
   ],
   "source": [
    "# def readfile(filename):\n",
    "#     return pd.read_csv(filename, sep=' ', header=None, keep_default_na=False, names=['words', 'labels'], skip_blank_lines=False, quoting=3)\n",
    "\n",
    "# train_df, dev_df, test_df = (readfile(f'{config.data_dir}{filename}') for filename in ['train.txt', 'dev.txt', 'test.txt'])\n",
    "# df = pd.concat([train_df, dev_df, test_df], ignore_index=True)\n",
    "\n",
    "train_test_ds = load_dataset('msra_ner', split='train+test')\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    "    train_test_ds['tokens'], \n",
    "    train_test_ds['ner_tags'], \n",
    "    test_size=config.test_split_size, \n",
    "    random_state=0\n",
    "    # shuffle=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, words, labels, config, word_pad_idx=0, label_pad_idx=-1):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config.bert_model, do_lower_case=True)\n",
    "        self.label2id = config.label2id\n",
    "        self.id2label = {_id: _label for _label, _id in list(config.label2id.items())}\n",
    "        self.dataset = self.preprocess(words, labels)\n",
    "        self.word_pad_idx = word_pad_idx\n",
    "        self.label_pad_idx = label_pad_idx\n",
    "        self.device = config.device\n",
    "\n",
    "    def preprocess(self, origin_sentences, origin_labels):\n",
    "        sentences = []\n",
    "        labels = []\n",
    "        for line, tag in zip(origin_sentences, origin_labels):\n",
    "            words = ['[CLS]'] + line[0:config.max_sequence_length-1]\n",
    "            label = [0] + tag[0:config.max_sequence_length-1]\n",
    "            token_start_idxs = np.arange(0, len(words))\n",
    "            sentences.append((self.tokenizer.convert_tokens_to_ids(words), token_start_idxs))\n",
    "            labels.append(label)\n",
    "\n",
    "            start = config.max_sequence_length-1\n",
    "            while len(tag) > start:\n",
    "                sub_words = ['[SEP]'] + line[start:start+config.max_sequence_length-1]\n",
    "                sub_label = [0] + tag[start:start+config.max_sequence_length-1]\n",
    "\n",
    "                token_start_idxs = np.arange(0, len(sub_words))\n",
    "                sentences.append((self.tokenizer.convert_tokens_to_ids(sub_words), token_start_idxs))\n",
    "                labels.append(sub_label)\n",
    "\n",
    "                start += config.max_sequence_length\n",
    "\n",
    "        data = [(sentence, label) for sentence, label in zip(sentences, labels)]\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"sample data to get batch\"\"\"\n",
    "        word = self.dataset[idx][0]\n",
    "        label = self.dataset[idx][1]\n",
    "        return [word, label]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"get dataset size\"\"\"\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        sentences = [x[0] for x in batch]\n",
    "        labels = [x[1] for x in batch]\n",
    "\n",
    "        # batch length\n",
    "        batch_len = len(sentences)\n",
    "\n",
    "        # compute length of longest sentence in batch\n",
    "        max_len = max([len(s[0]) for s in sentences])\n",
    "        max_label_len = 0\n",
    "\n",
    "        # padding data 初始化\n",
    "        batch_data = self.word_pad_idx * np.ones((batch_len, max_len), dtype=int)\n",
    "        batch_label_starts = []\n",
    "\n",
    "        # padding and aligning\n",
    "        for j in range(batch_len):\n",
    "            cur_len = len(sentences[j][0])\n",
    "            batch_data[j][:cur_len] = sentences[j][0]\n",
    "            label_start_idx = sentences[j][-1]\n",
    "            label_starts = np.zeros(max_len)\n",
    "            label_starts[[idx for idx in label_start_idx if idx < max_len]] = 1\n",
    "            batch_label_starts.append(label_starts)\n",
    "            max_label_len = max(int(sum(label_starts)), max_label_len)\n",
    "\n",
    "        # padding label\n",
    "        batch_labels = self.label_pad_idx * np.ones((batch_len, max_label_len))\n",
    "        for j in range(batch_len):\n",
    "            cur_tags_len = len(labels[j])\n",
    "            batch_labels[j][:cur_tags_len] = labels[j]\n",
    "\n",
    "        # convert data to torch LongTensors\n",
    "        batch_data = torch.tensor(np.array(batch_data, dtype=int), dtype=torch.long)\n",
    "        batch_label_starts = torch.tensor(np.array(batch_label_starts, dtype=int), dtype=torch.long)\n",
    "        batch_labels = torch.tensor(np.array(batch_labels, dtype=int), dtype=torch.long)\n",
    "\n",
    "        # shift tensors to GPU if available\n",
    "        batch_data, batch_label_starts = batch_data.to(self.device), batch_label_starts.to(self.device)\n",
    "        batch_labels = batch_labels.to(self.device)\n",
    "        return [batch_data, batch_label_starts, batch_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NERDataset(train_x, train_y, config)\n",
    "test_dataset = NERDataset(test_x, test_y, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, collate_fn=train_dataset.collate_fn) # shuffle=True\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.batch_size, collate_fn=test_dataset.collate_fn) # shuffle=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertNER(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super(BertNER, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.bert.resize_token_embeddings(len(train_dataset.tokenizer))\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.bert.embeddings.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=768,  # 1024\n",
    "            hidden_size=1024 // 2,  # 1024\n",
    "            batch_first=True,\n",
    "            num_layers=2,\n",
    "            dropout=0.5,  # 0.5\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.classifier = nn.Linear(1024, config.num_labels)\n",
    "        self.crf = CRF(config.num_labels, batch_first=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_data, token_type_ids=None, attention_mask=None, labels=None,\n",
    "                position_ids=None, inputs_embeds=None, head_mask=None):\n",
    "        input_ids, input_token_starts = input_data\n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids,\n",
    "                            position_ids=position_ids,\n",
    "                            head_mask=head_mask,\n",
    "                            inputs_embeds=inputs_embeds)\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        origin_sequence_output = [layer[starts.nonzero().squeeze(1)] for layer, starts in zip(sequence_output, input_token_starts)]\n",
    "\n",
    "        padded_sequence_output = pad_sequence(origin_sequence_output, batch_first=True)\n",
    "\n",
    "        padded_sequence_output = self.dropout(padded_sequence_output)\n",
    "        lstm_output, _ = self.bilstm(padded_sequence_output)\n",
    "\n",
    "        logits = self.classifier(lstm_output)\n",
    "        outputs = (logits,)\n",
    "        if labels is not None:\n",
    "            loss_mask = labels.gt(-1)\n",
    "            loss = self.crf(logits, labels, loss_mask) * (-1)\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertNER: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertNER from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertNER from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertNER were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'bilstm.weight_ih_l0', 'bilstm.weight_ih_l1_reverse', 'crf.end_transitions', 'crf.transitions', 'classifier.bias', 'bilstm.weight_hh_l0_reverse', 'bilstm.weight_ih_l1', 'bilstm.weight_hh_l0', 'bilstm.bias_ih_l0_reverse', 'crf.start_transitions', 'bilstm.bias_hh_l1', 'bilstm.bias_hh_l0', 'bilstm.bias_hh_l1_reverse', 'bilstm.bias_ih_l0', 'bilstm.weight_hh_l1', 'bilstm.bias_ih_l1', 'bilstm.weight_ih_l0_reverse', 'bilstm.bias_ih_l1_reverse', 'bilstm.weight_hh_l1_reverse', 'bilstm.bias_hh_l0_reverse']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/jovyan/anaconda3/envs/wimu-hw3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertNER(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (bilstm): LSTM(768, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (classifier): Linear(in_features=1024, out_features=7, bias=True)\n",
       "  (crf): CRF(num_tags=7)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertNER.from_pretrained(config.bert_model, num_labels=len(config.label2id))\n",
    "model.resize_token_embeddings(len(train_dataset.tokenizer)) \n",
    "\n",
    "bert_optimizer = list(model.bert.named_parameters())\n",
    "lstm_optimizer = list(model.bilstm.named_parameters())\n",
    "classifier_optimizer = list(model.classifier.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in bert_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': config.weight_decay},\n",
    "    {'params': [p for n, p in bert_optimizer if any(nd in n for nd in no_decay)],\n",
    "        'weight_decay': 0.0},\n",
    "    {'params': [p for n, p in lstm_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'lr': config.learning_rate * 5, 'weight_decay': config.weight_decay},\n",
    "    {'params': [p for n, p in lstm_optimizer if any(nd in n for nd in no_decay)],\n",
    "        'lr': config.learning_rate * 5, 'weight_decay': 0.0},\n",
    "    {'params': [p for n, p in classifier_optimizer if not any(nd in n for nd in no_decay)],\n",
    "        'lr': config.learning_rate * 5, 'weight_decay': config.weight_decay},\n",
    "    {'params': [p for n, p in classifier_optimizer if any(nd in n for nd in no_decay)],\n",
    "        'lr': config.learning_rate * 5, 'weight_decay': 0.0},\n",
    "    {'params': model.crf.parameters(), 'lr': config.learning_rate * 5}\n",
    "]\n",
    "    \n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=config.learning_rate, correct_bias=False)\n",
    "train_steps_per_epoch = len(train_dataset) // config.batch_size\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=(config.epoch_num // 10) * train_steps_per_epoch,\n",
    "                                            num_training_steps=config.epoch_num * train_steps_per_epoch)\n",
    "\n",
    "# model = nn.DataParallel(model)\n",
    "model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(seq):\n",
    "    \"\"\"\n",
    "    Gets entities from sequence.\n",
    "\n",
    "    Args:\n",
    "        seq (list): sequence of labels.\n",
    "\n",
    "    Returns:\n",
    "        list: list of (chunk_type, chunk_start, chunk_end).\n",
    "\n",
    "    Example:\n",
    "        seq = ['B-PER', 'I-PER', 'O', 'B-LOC']\n",
    "        get_entities(seq)\n",
    "        [('PER', 0, 1), ('LOC', 3, 3)]\n",
    "    \"\"\"\n",
    "    # for nested list\n",
    "    if any(isinstance(s, list) for s in seq):\n",
    "        seq = [item for sublist in seq for item in sublist + ['O']]\n",
    "    prev_tag = 'O'\n",
    "    prev_type = ''\n",
    "    begin_offset = 0\n",
    "    chunks = []\n",
    "    for i, chunk in enumerate(seq + ['O']):\n",
    "        tag = chunk[0]\n",
    "        type_ = chunk.split('-')[-1]\n",
    "\n",
    "        if end_of_chunk(prev_tag, tag, prev_type, type_):\n",
    "            chunks.append((prev_type, begin_offset, i - 1))\n",
    "        if start_of_chunk(prev_tag, tag, prev_type, type_):\n",
    "            begin_offset = i\n",
    "        prev_tag = tag\n",
    "        prev_type = type_\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def end_of_chunk(prev_tag, tag, prev_type, type_):\n",
    "    \"\"\"Checks if a chunk ended between the previous and current word.\n",
    "\n",
    "    Args:\n",
    "        prev_tag: previous chunk tag.\n",
    "        tag: current chunk tag.\n",
    "        prev_type: previous type.\n",
    "        type_: current type.\n",
    "\n",
    "    Returns:\n",
    "        chunk_end: boolean.\n",
    "    \"\"\"\n",
    "    chunk_end = False\n",
    "\n",
    "    if prev_tag == 'S':\n",
    "        chunk_end = True\n",
    "    # pred_label中可能出现这种情形\n",
    "    if prev_tag == 'B' and tag == 'B':\n",
    "        chunk_end = True\n",
    "    if prev_tag == 'B' and tag == 'S':\n",
    "        chunk_end = True\n",
    "    if prev_tag == 'B' and tag == 'O':\n",
    "        chunk_end = True\n",
    "    if prev_tag == 'I' and tag == 'B':\n",
    "        chunk_end = True\n",
    "    if prev_tag == 'I' and tag == 'S':\n",
    "        chunk_end = True\n",
    "    if prev_tag == 'I' and tag == 'O':\n",
    "        chunk_end = True\n",
    "\n",
    "    if prev_tag != 'O' and prev_tag != '.' and prev_type != type_:\n",
    "        chunk_end = True\n",
    "\n",
    "    return chunk_end\n",
    "\n",
    "\n",
    "def start_of_chunk(prev_tag, tag, prev_type, type_):\n",
    "    \"\"\"Checks if a chunk started between the previous and current word.\n",
    "\n",
    "    Args:\n",
    "        prev_tag: previous chunk tag.\n",
    "        tag: current chunk tag.\n",
    "        prev_type: previous type.\n",
    "        type_: current type.\n",
    "\n",
    "    Returns:\n",
    "        chunk_start: boolean.\n",
    "    \"\"\"\n",
    "    chunk_start = False\n",
    "\n",
    "    if tag == 'B':\n",
    "        chunk_start = True\n",
    "    if tag == 'S':\n",
    "        chunk_start = True\n",
    "\n",
    "    if prev_tag == 'S' and tag == 'I':\n",
    "        chunk_start = True\n",
    "    if prev_tag == 'O' and tag == 'I':\n",
    "        chunk_start = True\n",
    "\n",
    "    if tag != 'O' and tag != '.' and prev_type != type_:\n",
    "        chunk_start = True\n",
    "\n",
    "    return chunk_start\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred, mode='dev'):\n",
    "    \"\"\"Compute the F1 score.\n",
    "\n",
    "    The F1 score can be interpreted as a weighted average of the precision and\n",
    "    recall, where an F1 score reaches its best value at 1 and worst score at 0.\n",
    "    The relative contribution of precision and recall to the F1 score are\n",
    "    equal. The formula for the F1 score is::\n",
    "\n",
    "        F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    Args:\n",
    "        y_true : 2d array. Ground truth (correct) target values.\n",
    "        y_pred : 2d array. Estimated targets as returned by a tagger.\n",
    "\n",
    "    Returns:\n",
    "        score : float.\n",
    "\n",
    "    Example:\n",
    "        y_true = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    "        y_pred = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n",
    "        f1_score(y_true, y_pred)\n",
    "        0.50\n",
    "    \"\"\"\n",
    "    true_entities = set(get_entities(y_true))\n",
    "    pred_entities = set(get_entities(y_pred))\n",
    "    nb_correct = len(true_entities & pred_entities)\n",
    "    nb_pred = len(pred_entities)\n",
    "    nb_true = len(true_entities)\n",
    "\n",
    "    p = nb_correct / nb_pred if nb_pred > 0 else 0\n",
    "    r = nb_correct / nb_true if nb_true > 0 else 0\n",
    "    score = 2 * p * r / (p + r) if p + r > 0 else 0\n",
    "    if mode == 'dev':\n",
    "        return score\n",
    "    else:\n",
    "        f_score = {}\n",
    "        for label in config.labels:\n",
    "            true_entities_label = set()\n",
    "            pred_entities_label = set()\n",
    "            for t in true_entities:\n",
    "                if t[0] == label:\n",
    "                    true_entities_label.add(t)\n",
    "            for p in pred_entities:\n",
    "                if p[0] == label:\n",
    "                    pred_entities_label.add(p)\n",
    "            nb_correct_label = len(true_entities_label & pred_entities_label)\n",
    "            nb_pred_label = len(pred_entities_label)\n",
    "            nb_true_label = len(true_entities_label)\n",
    "\n",
    "            p_label = nb_correct_label / nb_pred_label if nb_pred_label > 0 else 0\n",
    "            r_label = nb_correct_label / nb_true_label if nb_true_label > 0 else 0\n",
    "            score_label = 2 * p_label * r_label / (p_label + r_label) if p_label + r_label > 0 else 0\n",
    "            f_score[label] = score_label\n",
    "        return f_score, score\n",
    "\n",
    "\n",
    "def bad_case(y_true, y_pred, data):\n",
    "    if not os.path.exists(config.case_dir):\n",
    "        os.system(r\"touch {}\".format(config.case_dir))\n",
    "    output = open(config.case_dir, 'w')\n",
    "    for idx, (t, p) in enumerate(zip(y_true, y_pred)):\n",
    "        if t == p:\n",
    "            continue\n",
    "        else:\n",
    "            output.write(\"bad case \" + str(idx) + \": \\n\")\n",
    "            output.write(\"sentence: \" + str(data[idx]) + \"\\n\")\n",
    "            output.write(\"golden label: \" + str(t) + \"\\n\")\n",
    "            output.write(\"model pred: \" + str(p) + \"\\n\")\n",
    "    logging.info(\"--------Bad Cases reserved !--------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 110>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000009vscode-remote?line=106'>107</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m metrics\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000009vscode-remote?line=108'>109</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000009vscode-remote?line=109'>110</a>\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m--------Start Training!--------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000009vscode-remote?line=110'>111</a>\u001b[0m train(train_loader, test_loader, model, optimizer, scheduler, config\u001b[39m.\u001b[39mmodel_dir)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "def train_epoch(train_loader, model, optimizer, scheduler, epoch):\n",
    "    # set model to training mode\n",
    "    model.train()\n",
    "    # step number in one epoch: 336\n",
    "    train_losses = 0\n",
    "    for idx, batch_samples in enumerate(tqdm(train_loader)):\n",
    "        batch_data, batch_token_starts, batch_labels = batch_samples\n",
    "        batch_masks = batch_data.gt(0)  # get padding mask\n",
    "        # compute model output and loss\n",
    "        loss = model((batch_data, batch_token_starts),\n",
    "                     token_type_ids=None, attention_mask=batch_masks, labels=batch_labels)[0]\n",
    "        train_losses += loss.item()\n",
    "        # clear previous gradients, compute gradients of all variables wrt loss\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        # gradient clipping\n",
    "        nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=config.clip_grad)\n",
    "        # performs updates using calculated gradients\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    train_loss = float(train_losses) / len(train_loader)\n",
    "    logging.info(\"Epoch: {}, train loss: {}\".format(epoch, train_loss))\n",
    "\n",
    "\n",
    "def train(train_loader, dev_loader, model, optimizer, scheduler, model_dir):\n",
    "    \"\"\"train the model and test model performance\"\"\"\n",
    "    # reload weights from restore_dir if specified\n",
    "    if model_dir is not None and config.load_before:\n",
    "        model = BertNER.from_pretrained(model_dir)\n",
    "        model.to(config.device)\n",
    "        logging.info(\"--------Load model from {}--------\".format(model_dir))\n",
    "    best_val_f1 = 0.0\n",
    "    patience_counter = 0\n",
    "    # start training\n",
    "    for epoch in range(1, config.epoch_num + 1):\n",
    "        train_epoch(train_loader, model, optimizer, scheduler, epoch)\n",
    "        val_metrics = evaluate(dev_loader, model, mode='dev')\n",
    "        val_f1 = val_metrics['f1']\n",
    "        logging.info(\"Epoch: {}, dev loss: {}, f1 score: {}\".format(epoch, val_metrics['loss'], val_f1))\n",
    "        improve_f1 = val_f1 - best_val_f1\n",
    "        if improve_f1 > 1e-5:\n",
    "            best_val_f1 = val_f1\n",
    "            model.save_pretrained(model_dir)\n",
    "            logging.info(\"--------Save best model!--------\")\n",
    "            if improve_f1 < config.patience:\n",
    "                patience_counter += 1\n",
    "            else:\n",
    "                patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        # Early stopping and logging best f1\n",
    "        if (patience_counter >= config.patience_num and epoch > config.min_epoch_num) or epoch == config.epoch_num:\n",
    "            logging.info(\"Best val f1: {}\".format(best_val_f1))\n",
    "            break\n",
    "    logging.info(\"Training Finished!\")\n",
    "\n",
    "\n",
    "def evaluate(dev_loader, model, mode='dev'):\n",
    "    # set model to evaluation mode\n",
    "    model.eval()\n",
    "    if mode == 'test':\n",
    "        tokenizer = AutoTokenizer.from_pretrained(config.bert_model, do_lower_case=True, skip_special_tokens=True)\n",
    "    id2label = config.id2label\n",
    "    true_tags = []\n",
    "    pred_tags = []\n",
    "    sent_data = []\n",
    "    dev_losses = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch_samples in enumerate(dev_loader):\n",
    "            batch_data, batch_token_starts, batch_tags = batch_samples\n",
    "            if mode == 'test':\n",
    "                sent_data.extend([[tokenizer.convert_ids_to_tokens(idx.item()) for idx in indices\n",
    "                                   if (idx.item() > 0 and idx.item() != 101)] for indices in batch_data])\n",
    "            batch_masks = batch_data.gt(0)  # get padding mask, gt(x): get index greater than x\n",
    "            label_masks = batch_tags.gt(-1)  # get padding mask, gt(x): get index greater than x\n",
    "            # compute model output and loss\n",
    "            loss = model((batch_data, batch_token_starts),\n",
    "                         token_type_ids=None, attention_mask=batch_masks, labels=batch_tags)[0]\n",
    "            dev_losses += loss.item()\n",
    "            # (batch_size, max_len, num_labels)\n",
    "            batch_output = model((batch_data, batch_token_starts),\n",
    "                                 token_type_ids=None, attention_mask=batch_masks)[0]\n",
    "            # (batch_size, max_len - padding_label_len)\n",
    "            batch_output = model.crf.decode(batch_output, mask=label_masks)\n",
    "            # (batch_size, max_len)\n",
    "            batch_tags = batch_tags.to('cpu').numpy()\n",
    "            pred_tags.extend([[id2label.get(idx) for idx in indices] for indices in batch_output])\n",
    "            # (batch_size, max_len - padding_label_len)\n",
    "            true_tags.extend([[id2label.get(idx) for idx in indices if idx > -1] for indices in batch_tags])\n",
    "\n",
    "    assert len(pred_tags) == len(true_tags)\n",
    "    if mode == 'test':\n",
    "        assert len(sent_data) == len(true_tags)\n",
    "\n",
    "    # logging loss, f1 and report\n",
    "    metrics = {}\n",
    "    if mode == 'dev':\n",
    "        f1 = f1_score(true_tags, pred_tags, mode)\n",
    "        metrics['f1'] = f1\n",
    "    else:\n",
    "        bad_case(true_tags, pred_tags, sent_data)\n",
    "        f1_labels, f1 = f1_score(true_tags, pred_tags, mode)\n",
    "        metrics['f1_labels'] = f1_labels\n",
    "        metrics['f1'] = f1\n",
    "    metrics['loss'] = float(dev_losses) / len(dev_loader)\n",
    "    return metrics\n",
    "\n",
    "# Train the model\n",
    "logging.info(\"--------Start Training!--------\")\n",
    "train(train_loader, test_loader, model, optimizer, scheduler, config.model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'config' has no attribute 'case_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000010vscode-remote?line=0'>1</a>\u001b[0m val_metrics \u001b[39m=\u001b[39m evaluate(test_loader, model, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000010vscode-remote?line=1'>2</a>\u001b[0m val_f1 \u001b[39m=\u001b[39m val_metrics[\u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000010vscode-remote?line=2'>3</a>\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mtest loss: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, f1 score: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(val_metrics[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m], val_f1))\n",
      "\u001b[1;32m/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb Cell 10'\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dev_loader, model, mode)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000009vscode-remote?line=99'>100</a>\u001b[0m     metrics[\u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m f1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000009vscode-remote?line=100'>101</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000009vscode-remote?line=101'>102</a>\u001b[0m     bad_case(true_tags, pred_tags, sent_data)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000009vscode-remote?line=102'>103</a>\u001b[0m     f1_labels, f1 \u001b[39m=\u001b[39m f1_score(true_tags, pred_tags, mode)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000009vscode-remote?line=103'>104</a>\u001b[0m     metrics[\u001b[39m'\u001b[39m\u001b[39mf1_labels\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m f1_labels\n",
      "\u001b[1;32m/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb Cell 9'\u001b[0m in \u001b[0;36mbad_case\u001b[0;34m(y_true, y_pred, data)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000008vscode-remote?line=158'>159</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbad_case\u001b[39m(y_true, y_pred, data):\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000008vscode-remote?line=159'>160</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(config\u001b[39m.\u001b[39;49mcase_dir):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000008vscode-remote?line=160'>161</a>\u001b[0m         os\u001b[39m.\u001b[39msystem(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtouch \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(config\u001b[39m.\u001b[39mcase_dir))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdgx/home/jovyan/projects/course-web-intelligence-and-message-understanding/homework-3/main.ipynb#ch0000008vscode-remote?line=161'>162</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(config\u001b[39m.\u001b[39mcase_dir, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'config' has no attribute 'case_dir'"
     ]
    }
   ],
   "source": [
    "val_metrics = evaluate(test_loader, model, mode='test')\n",
    "val_f1 = val_metrics['f1']\n",
    "logging.info(\"test loss: {}, f1 score: {}\".format(val_metrics['loss'], val_f1))\n",
    "val_f1_labels = val_metrics['f1_labels']\n",
    "for label in config.labels:\n",
    "    logging.info(\"f1 score of {}: {}\".format(label, val_f1_labels[label]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "78541f15f2c4b81d86ddddb6e86bf971ec7142090c10c1d6650bca46129399f8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
