{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from valentine import valentine_match, valentine_metrics\n",
    "from valentine.algorithms import Coma, Cupid, DistributionBased, SimilarityFlooding, JaccardLevenMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'pair_10'\n",
    "data_path = f'./Data/{name}/'\n",
    "df1 = pd.read_csv(os.path.join(data_path, 'Table1.csv'))\n",
    "df2 = pd.read_csv(os.path.join(data_path, 'Table2.csv'))\n",
    "\n",
    "matcher = SimilarityFlooding()\n",
    "matches = valentine_match(df1, df2, matcher)\n",
    "\n",
    "result = {}\n",
    "for match in matches:\n",
    "    temp = result.get(match[0][1], {})\n",
    "    temp[match[1][1]]  = matches[match]\n",
    "    result[match[0][1]] = temp\n",
    "\n",
    "result_path = f'./Result/{name}.csv'\n",
    "df = pd.DataFrame(result)\n",
    "df.to_csv(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.8333333333333334,\n",
       " 'recall': 0.625,\n",
       " 'f1_score': 0.7142857142857143,\n",
       " 'precision_at_10_percent': 0.5,\n",
       " 'precision_at_30_percent': 0.2,\n",
       " 'precision_at_50_percent': 0.14,\n",
       " 'precision_at_70_percent': 0.1,\n",
       " 'precision_at_90_percent': 0.08888888888888889,\n",
       " 'recall_at_sizeof_ground_truth': 0.625}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = [tuple(line.strip('<>\\n').split(', ')) for line in open(os.path.join(data_path, 'mapping.txt')).readlines()]\n",
    "\n",
    "def one_to_one_matches(matches: dict):\n",
    "    set_match_values = set(matches.values())\n",
    "\n",
    "    if len(set_match_values) < 2:\n",
    "        return matches\n",
    "\n",
    "    matched = dict()\n",
    "\n",
    "    for key in matches.keys():\n",
    "        matched[key[0]] = False\n",
    "        matched[key[1]] = False\n",
    "\n",
    "    median = list(set_match_values)[math.ceil(len(set_match_values)/2)]\n",
    "\n",
    "    matches1to1 = dict()\n",
    "\n",
    "    for key in matches.keys():\n",
    "        if (not matched[key[0]]) and (not matched[key[1]]):\n",
    "            similarity = matches.get(key)\n",
    "            if similarity >= median:\n",
    "                matches1to1[key] = similarity\n",
    "                matched[key[0]] = True\n",
    "                matched[key[1]] = True\n",
    "            else:\n",
    "                break\n",
    "    return matches1to1\n",
    "\n",
    "metrics = valentine_metrics.all_metrics(matches, ground_truth)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchers = [Coma, Cupid, DistributionBased, SimilarityFlooding, JaccardLevenMatcher]\n",
    "metrics = []\n",
    "for i in range(1, 15):\n",
    "    path = f'./dataset/raw/Training Data/pair_{i}/'\n",
    "    df1 = pd.read_csv(os.path.join(path, 'Table1.csv'))\n",
    "    df2 = pd.read_csv(os.path.join(path, 'Table2.csv'))\n",
    "    ground_truth = [tuple(line.strip('<>\\n').split(', ')) for line in open(os.path.join(path, 'mapping.txt')).readlines()]\n",
    "\n",
    "    sub_metrics = []\n",
    "    for j, matcher in enumerate(matchers):\n",
    "        matches = valentine_match(df1, df2, matcher())\n",
    "        sub_metrics.append(valentine_metrics.all_metrics(matches, ground_truth))\n",
    "\n",
    "    metrics.append(sub_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'precision': 0.6904761904761905,\n",
       "  'recall': 0.5291666666666666,\n",
       "  'f1_score': 0.5891434307583376,\n",
       "  'precision_at_10_percent': 0.7142857142857143,\n",
       "  'precision_at_30_percent': 0.7142857142857143,\n",
       "  'precision_at_50_percent': 0.6904761904761906,\n",
       "  'precision_at_70_percent': 0.6726190476190476,\n",
       "  'precision_at_90_percent': 0.6321428571428571,\n",
       "  'recall_at_sizeof_ground_truth': 0.5791666666666666},\n",
       " {'precision': 0.6678571428571428,\n",
       "  'recall': 0.40535714285714286,\n",
       "  'f1_score': 0.4799863670164422,\n",
       "  'precision_at_10_percent': 0.7142857142857143,\n",
       "  'precision_at_30_percent': 0.6857142857142857,\n",
       "  'precision_at_50_percent': 0.6547619047619048,\n",
       "  'precision_at_70_percent': 0.5416666666666666,\n",
       "  'precision_at_90_percent': 0.4979591836734694,\n",
       "  'recall_at_sizeof_ground_truth': 0.4583333333333333},\n",
       " {'precision': 0.21428571428571427,\n",
       "  'recall': 0.04107142857142857,\n",
       "  'f1_score': 0.06825396825396826,\n",
       "  'precision_at_10_percent': 0.21428571428571427,\n",
       "  'precision_at_30_percent': 0.21428571428571427,\n",
       "  'precision_at_50_percent': 0.21428571428571427,\n",
       "  'precision_at_70_percent': 0.21428571428571427,\n",
       "  'precision_at_90_percent': 0.21428571428571427,\n",
       "  'recall_at_sizeof_ground_truth': 0.04107142857142857},\n",
       " {'precision': 0.786734693877551,\n",
       "  'recall': 0.705357142857143,\n",
       "  'f1_score': 0.7297876726448155,\n",
       "  'precision_at_10_percent': 0.6430719656283567,\n",
       "  'precision_at_30_percent': 0.3603811862740434,\n",
       "  'precision_at_50_percent': 0.2585819927640204,\n",
       "  'precision_at_70_percent': 0.19127955147658682,\n",
       "  'precision_at_90_percent': 0.15375712918927237,\n",
       "  'recall_at_sizeof_ground_truth': 0.6220238095238094},\n",
       " {'precision': 0.5833333333333333,\n",
       "  'recall': 0.18154761904761904,\n",
       "  'f1_score': 0.26995980210265924,\n",
       "  'precision_at_10_percent': 0.6309523809523808,\n",
       "  'precision_at_30_percent': 0.5918367346938774,\n",
       "  'precision_at_50_percent': 0.5963203463203463,\n",
       "  'precision_at_70_percent': 0.5996031746031747,\n",
       "  'precision_at_90_percent': 0.5741569833675096,\n",
       "  'recall_at_sizeof_ground_truth': 0.24345238095238098}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_metrics = [0] * 5\n",
    "for i in range(5):\n",
    "    average_metrics[i] = {}\n",
    "    for j in metrics:\n",
    "        for key in j[i]:\n",
    "            average_metrics[i][key] = average_metrics[i].get(key, 0) + j[i][key]\n",
    "    \n",
    "    for key in average_metrics[i]:\n",
    "        average_metrics[i][key] /= len(metrics)\n",
    "    \n",
    "average_metrics"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf19390a18042979714ec96478f61902827e0965e1082e7ebcbb5e9ac25b9090"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('py310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
